{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "547bb763-2f2f-421b-ac35-e2dd0c46c245",
   "metadata": {},
   "source": [
    "## インド　インターンシップ　サンプルコード"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ed06a1",
   "metadata": {},
   "source": [
    "### Opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "475aa0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Haar Cascadeの分類器（顔検出用）の読み込み\n",
    "# OpenCVに付属しているカスケードファイルを使用\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye_tree_eyeglasses.xml')\n",
    "\n",
    "# 画像を読み込む場合（ファイル指定）\n",
    "# img = cv2.imread(\"sample.jpg\")\n",
    "\n",
    "# Webカメラから取得する場合\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # グレースケールに変換（Haarはグレースケールで動作）\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 顔検出（scaleFactor:縮小率, minNeighbors:検出精度）\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # 検出した顔に矩形を描画\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Face Detection', frame)\n",
    "\n",
    "    # ESCキーで終了\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2758f3f6",
   "metadata": {},
   "source": [
    "### YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bfed06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100%|██████████| 5.35M/5.35M [00:06<00:00, 844kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 91.6ms\n",
      "Speed: 3.4ms preprocess, 91.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 136.3ms\n",
      "Speed: 3.7ms preprocess, 136.3ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 106.2ms\n",
      "Speed: 5.4ms preprocess, 106.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 87.0ms\n",
      "Speed: 4.0ms preprocess, 87.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 96.4ms\n",
      "Speed: 3.2ms preprocess, 96.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 87.1ms\n",
      "Speed: 3.3ms preprocess, 87.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 85.2ms\n",
      "Speed: 3.0ms preprocess, 85.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 89.8ms\n",
      "Speed: 4.4ms preprocess, 89.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 99.4ms\n",
      "Speed: 3.8ms preprocess, 99.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 89.8ms\n",
      "Speed: 2.9ms preprocess, 89.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 90.3ms\n",
      "Speed: 2.9ms preprocess, 90.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 84.0ms\n",
      "Speed: 3.5ms preprocess, 84.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 89.5ms\n",
      "Speed: 3.7ms preprocess, 89.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 86.0ms\n",
      "Speed: 2.7ms preprocess, 86.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 88.1ms\n",
      "Speed: 3.2ms preprocess, 88.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 85.5ms\n",
      "Speed: 2.8ms preprocess, 85.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.1ms\n",
      "Speed: 3.8ms preprocess, 83.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 91.8ms\n",
      "Speed: 3.4ms preprocess, 91.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 105.1ms\n",
      "Speed: 3.1ms preprocess, 105.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 123.9ms\n",
      "Speed: 4.2ms preprocess, 123.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 108.8ms\n",
      "Speed: 3.5ms preprocess, 108.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 86.4ms\n",
      "Speed: 2.9ms preprocess, 86.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 97.6ms\n",
      "Speed: 3.0ms preprocess, 97.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 87.7ms\n",
      "Speed: 3.6ms preprocess, 87.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 85.8ms\n",
      "Speed: 2.6ms preprocess, 85.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 91.2ms\n",
      "Speed: 3.0ms preprocess, 91.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 98.7ms\n",
      "Speed: 3.2ms preprocess, 98.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 150.4ms\n",
      "Speed: 3.1ms preprocess, 150.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 80.1ms\n",
      "Speed: 3.4ms preprocess, 80.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.1ms\n",
      "Speed: 2.9ms preprocess, 76.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 92.9ms\n",
      "Speed: 2.6ms preprocess, 92.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 96.8ms\n",
      "Speed: 2.8ms preprocess, 96.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 88.9ms\n",
      "Speed: 5.9ms preprocess, 88.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 90.7ms\n",
      "Speed: 3.5ms preprocess, 90.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 85.4ms\n",
      "Speed: 3.7ms preprocess, 85.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 100.5ms\n",
      "Speed: 3.3ms preprocess, 100.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.0ms\n",
      "Speed: 3.0ms preprocess, 83.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 87.8ms\n",
      "Speed: 3.4ms preprocess, 87.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.3ms\n",
      "Speed: 2.9ms preprocess, 81.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 97.0ms\n",
      "Speed: 2.5ms preprocess, 97.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 82.4ms\n",
      "Speed: 2.8ms preprocess, 82.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 84.7ms\n",
      "Speed: 3.4ms preprocess, 84.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 89.2ms\n",
      "Speed: 2.7ms preprocess, 89.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 95.7ms\n",
      "Speed: 3.3ms preprocess, 95.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 97.7ms\n",
      "Speed: 3.6ms preprocess, 97.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.7ms\n",
      "Speed: 3.5ms preprocess, 78.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.4ms\n",
      "Speed: 2.6ms preprocess, 63.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.9ms\n",
      "Speed: 2.5ms preprocess, 66.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 67.5ms\n",
      "Speed: 2.8ms preprocess, 67.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.1ms\n",
      "Speed: 3.2ms preprocess, 60.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.4ms\n",
      "Speed: 2.6ms preprocess, 63.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.6ms\n",
      "Speed: 21.9ms preprocess, 81.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 tvs, 63.2ms\n",
      "Speed: 3.1ms preprocess, 63.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 tvs, 62.0ms\n",
      "Speed: 2.6ms preprocess, 62.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 64.8ms\n",
      "Speed: 2.7ms preprocess, 64.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 tvs, 60.1ms\n",
      "Speed: 2.9ms preprocess, 60.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.8ms\n",
      "Speed: 2.6ms preprocess, 62.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 bottles, 60.8ms\n",
      "Speed: 2.7ms preprocess, 60.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 57.1ms\n",
      "Speed: 3.0ms preprocess, 57.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bottle, 62.5ms\n",
      "Speed: 2.5ms preprocess, 62.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 65.5ms\n",
      "Speed: 3.0ms preprocess, 65.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bottle, 68.1ms\n",
      "Speed: 2.8ms preprocess, 68.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 64.2ms\n",
      "Speed: 2.5ms preprocess, 64.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 73.6ms\n",
      "Speed: 2.9ms preprocess, 73.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 66.2ms\n",
      "Speed: 2.9ms preprocess, 66.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bottle, 69.2ms\n",
      "Speed: 2.8ms preprocess, 69.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bottle, 91.2ms\n",
      "Speed: 3.5ms preprocess, 91.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 77.6ms\n",
      "Speed: 3.4ms preprocess, 77.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 67.8ms\n",
      "Speed: 3.2ms preprocess, 67.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 70.3ms\n",
      "Speed: 3.6ms preprocess, 70.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bottle, 73.4ms\n",
      "Speed: 2.8ms preprocess, 73.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.2ms\n",
      "Speed: 2.7ms preprocess, 66.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.0ms\n",
      "Speed: 2.8ms preprocess, 75.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 2 tvs, 75.6ms\n",
      "Speed: 3.6ms preprocess, 75.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 2 tvs, 85.5ms\n",
      "Speed: 3.7ms preprocess, 85.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 tv, 86.6ms\n",
      "Speed: 7.4ms preprocess, 86.6ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.3ms\n",
      "Speed: 3.6ms preprocess, 76.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 75.3ms\n",
      "Speed: 3.3ms preprocess, 75.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 71.8ms\n",
      "Speed: 4.0ms preprocess, 71.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 tv, 74.1ms\n",
      "Speed: 3.4ms preprocess, 74.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 tv, 74.4ms\n",
      "Speed: 2.7ms preprocess, 74.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 ties, 1 chair, 1 tv, 77.7ms\n",
      "Speed: 3.2ms preprocess, 77.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 tvs, 74.7ms\n",
      "Speed: 2.9ms preprocess, 74.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 1 tv, 70.0ms\n",
      "Speed: 2.7ms preprocess, 70.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 2 tvs, 81.0ms\n",
      "Speed: 3.8ms preprocess, 81.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 1 tv, 78.6ms\n",
      "Speed: 2.7ms preprocess, 78.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 2 tvs, 74.4ms\n",
      "Speed: 4.0ms preprocess, 74.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 1 tv, 83.0ms\n",
      "Speed: 2.5ms preprocess, 83.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 2 tvs, 76.9ms\n",
      "Speed: 2.6ms preprocess, 76.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 1 tv, 73.2ms\n",
      "Speed: 3.0ms preprocess, 73.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 2 tvs, 76.0ms\n",
      "Speed: 3.4ms preprocess, 76.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 1 tv, 73.5ms\n",
      "Speed: 3.2ms preprocess, 73.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 2 tvs, 66.4ms\n",
      "Speed: 3.1ms preprocess, 66.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 1 tv, 85.2ms\n",
      "Speed: 3.4ms preprocess, 85.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 2 tvs, 186.7ms\n",
      "Speed: 6.7ms preprocess, 186.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 2 tvs, 109.3ms\n",
      "Speed: 5.5ms preprocess, 109.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 chair, 1 tv, 63.0ms\n",
      "Speed: 2.7ms preprocess, 63.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 wine glass, 1 tv, 62.2ms\n",
      "Speed: 2.6ms preprocess, 62.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 chair, 1 tv, 104.4ms\n",
      "Speed: 2.5ms preprocess, 104.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 tv, 58.5ms\n",
      "Speed: 3.1ms preprocess, 58.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 2 tvs, 65.0ms\n",
      "Speed: 2.9ms preprocess, 65.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 tv, 64.2ms\n",
      "Speed: 2.6ms preprocess, 64.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 tv, 62.3ms\n",
      "Speed: 2.6ms preprocess, 62.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 1 tv, 66.6ms\n",
      "Speed: 2.9ms preprocess, 66.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 tv, 66.0ms\n",
      "Speed: 3.1ms preprocess, 66.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 tv, 60.2ms\n",
      "Speed: 2.7ms preprocess, 60.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 2 tvs, 66.8ms\n",
      "Speed: 2.6ms preprocess, 66.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 tv, 63.7ms\n",
      "Speed: 2.9ms preprocess, 63.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 1 tv, 69.1ms\n",
      "Speed: 13.0ms preprocess, 69.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 2 tvs, 140.8ms\n",
      "Speed: 3.8ms preprocess, 140.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 2 tvs, 148.3ms\n",
      "Speed: 5.6ms preprocess, 148.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 1 tv, 71.4ms\n",
      "Speed: 3.9ms preprocess, 71.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 1 tv, 67.3ms\n",
      "Speed: 2.9ms preprocess, 67.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 1 tv, 55.4ms\n",
      "Speed: 2.1ms preprocess, 55.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 1 tv, 58.9ms\n",
      "Speed: 2.9ms preprocess, 58.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 2 tvs, 56.6ms\n",
      "Speed: 2.5ms preprocess, 56.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 1 tv, 67.7ms\n",
      "Speed: 3.2ms preprocess, 67.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 1 tv, 70.0ms\n",
      "Speed: 2.8ms preprocess, 70.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 2 tvs, 75.1ms\n",
      "Speed: 2.6ms preprocess, 75.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 2 tvs, 97.0ms\n",
      "Speed: 11.4ms preprocess, 97.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 1 tv, 69.8ms\n",
      "Speed: 3.5ms preprocess, 69.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 2 tvs, 65.1ms\n",
      "Speed: 3.1ms preprocess, 65.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 2 tvs, 78.5ms\n",
      "Speed: 3.1ms preprocess, 78.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 1 tv, 73.6ms\n",
      "Speed: 3.3ms preprocess, 73.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 2 tvs, 68.3ms\n",
      "Speed: 3.5ms preprocess, 68.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 1 tv, 72.6ms\n",
      "Speed: 3.5ms preprocess, 72.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 1 tv, 69.0ms\n",
      "Speed: 2.9ms preprocess, 69.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 2 tvs, 76.4ms\n",
      "Speed: 3.1ms preprocess, 76.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 2 tvs, 70.4ms\n",
      "Speed: 2.5ms preprocess, 70.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 2 tvs, 70.1ms\n",
      "Speed: 2.8ms preprocess, 70.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 1 tv, 76.3ms\n",
      "Speed: 3.0ms preprocess, 76.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 1 tv, 79.1ms\n",
      "Speed: 3.5ms preprocess, 79.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 1 tv, 67.7ms\n",
      "Speed: 3.1ms preprocess, 67.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 bottle, 2 tvs, 58.9ms\n",
      "Speed: 2.8ms preprocess, 58.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 ties, 1 tv, 73.3ms\n",
      "Speed: 2.8ms preprocess, 73.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 70.2ms\n",
      "Speed: 2.8ms preprocess, 70.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 68.2ms\n",
      "Speed: 2.7ms preprocess, 68.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.7ms\n",
      "Speed: 2.8ms preprocess, 62.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tv, 66.4ms\n",
      "Speed: 2.5ms preprocess, 66.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 72.1ms\n",
      "Speed: 2.7ms preprocess, 72.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.4ms\n",
      "Speed: 3.3ms preprocess, 76.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.6ms\n",
      "Speed: 2.6ms preprocess, 59.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 65.5ms\n",
      "Speed: 2.5ms preprocess, 65.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.6ms\n",
      "Speed: 2.6ms preprocess, 66.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 61.4ms\n",
      "Speed: 2.3ms preprocess, 61.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.7ms\n",
      "Speed: 2.6ms preprocess, 60.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 58.7ms\n",
      "Speed: 2.6ms preprocess, 58.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 62.4ms\n",
      "Speed: 2.7ms preprocess, 62.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.1ms\n",
      "Speed: 2.6ms preprocess, 59.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 61.9ms\n",
      "Speed: 2.5ms preprocess, 61.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 58.3ms\n",
      "Speed: 2.8ms preprocess, 58.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.5ms\n",
      "Speed: 2.4ms preprocess, 59.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 64.4ms\n",
      "Speed: 2.7ms preprocess, 64.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.6ms\n",
      "Speed: 3.0ms preprocess, 60.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.4ms\n",
      "Speed: 2.8ms preprocess, 66.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.2ms\n",
      "Speed: 2.6ms preprocess, 60.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 64.7ms\n",
      "Speed: 2.8ms preprocess, 64.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.2ms\n",
      "Speed: 3.0ms preprocess, 66.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.6ms\n",
      "Speed: 2.5ms preprocess, 59.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.0ms\n",
      "Speed: 2.3ms preprocess, 63.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.1ms\n",
      "Speed: 2.7ms preprocess, 59.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 73.4ms\n",
      "Speed: 3.8ms preprocess, 73.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 65.6ms\n",
      "Speed: 2.7ms preprocess, 65.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO('yolo11n.pt')\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        # Run YOLOv8 inference on the frame\n",
    "        results = model(frame)\n",
    "\n",
    "        # Visualize the results on the frame\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # Display the annotated frame\n",
    "        cv2.imshow(\"YOLOv8 Inference\", annotated_frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630a17d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== キャプチャ開始 ===\n",
      "Cキー: Drowsy に保存 / Oキー: Non Drowsy に保存 / Qキー: 終了\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002345_933452.png （合計 1 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002346_167643.png （合計 2 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002346_331908.png （合計 3 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002346_565079.png （合計 4 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002346_734680.png （合計 5 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002346_966318.png （合計 6 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002347_165054.png （合計 7 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002347_434876.png （合計 8 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002347_601064.png （合計 9 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002347_833595.png （合計 10 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002352_735938.png （合計 11 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002352_929314.png （合計 12 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002353_134075.png （合計 13 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002353_295654.png （合計 14 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002353_528786.png （合計 15 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002353_762299.png （合計 16 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002353_928752.png （合計 17 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002354_128938.png （合計 18 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002354_362090.png （合計 19 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002354_561849.png （合計 20 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002354_763152.png （合計 21 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002354_965572.png （合計 22 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002355_195059.png （合計 23 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002355_428375.png （合計 24 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002355_628108.png （合計 25 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002355_861283.png （合計 26 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002356_094616.png （合計 27 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002356_328238.png （合計 28 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002356_558745.png （合計 29 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002356_762095.png （合計 30 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002356_995161.png （合計 31 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002357_194255.png （合計 32 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002357_394065.png （合計 33 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002357_594129.png （合計 34 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002357_795023.png （合計 35 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002357_993777.png （合計 36 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002358_193961.png （合計 37 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002358_593788.png （合計 38 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002358_794379.png （合計 39 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002358_965084.png （合計 40 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002359_171282.png （合計 41 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002359_296937.png （合計 42 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002359_429361.png （合計 43 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002359_626848.png （合計 44 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002359_826312.png （合計 45 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002400_026952.png （合計 46 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002400_226346.png （合計 47 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002400_426089.png （合計 48 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002400_626059.png （合計 49 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002400_827205.png （合計 50 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002401_060928.png （合計 51 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002401_226075.png （合計 52 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002401_426508.png （合計 53 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002401_625831.png （合計 54 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002401_894144.png （合計 55 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002402_092466.png （合計 56 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002402_325731.png （合計 57 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002402_492418.png （合計 58 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002402_759397.png （合計 59 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002402_926829.png （合計 60 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002403_095755.png （合計 61 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002403_294853.png （合計 62 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002403_462987.png （合計 63 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002403_594823.png （合計 64 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002403_692864.png （合計 65 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002403_860073.png （合計 66 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002404_058592.png （合計 67 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002404_258654.png （合計 68 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002404_425576.png （合計 69 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002404_591866.png （合計 70 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002404_792888.png （合計 71 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002404_925889.png （合計 72 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002405_230094.png （合計 73 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002405_429871.png （合計 74 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002405_592255.png （合計 75 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002405_790826.png （合計 76 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002405_958291.png （合計 77 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002406_157432.png （合計 78 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002406_330046.png （合計 79 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002406_492118.png （合計 80 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002406_725960.png （合計 81 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002406_896285.png （合計 82 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002407_057822.png （合計 83 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002407_258826.png （合計 84 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002407_657241.png （合計 85 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002407_825187.png （合計 86 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002408_023860.png （合計 87 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002408_291691.png （合計 88 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002408_557928.png （合計 89 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002408_761376.png （合計 90 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002408_960106.png （合計 91 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002409_128984.png （合計 92 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002409_325422.png （合計 93 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002409_526939.png （合計 94 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002409_694676.png （合計 95 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002409_955622.png （合計 96 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002410_156606.png （合計 97 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002410_422808.png （合計 98 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002410_656118.png （合計 99 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002410_856746.png （合計 100 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002411_055073.png （合計 101 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002411_255366.png （合計 102 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002411_489079.png （合計 103 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002411_689644.png （合計 104 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002411_923304.png （合計 105 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002412_188572.png （合計 106 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002412_389281.png （合計 107 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002412_622674.png （合計 108 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002412_821839.png （合計 109 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002413_191241.png （合計 110 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002413_387955.png （合計 111 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002413_587508.png （合計 112 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002413_821417.png （合計 113 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002413_987305.png （合計 114 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002414_187565.png （合計 115 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002414_320821.png （合計 116 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002414_487951.png （合計 117 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002414_653877.png （合計 118 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002414_955641.png （合計 119 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002415_290640.png （合計 120 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002415_453396.png （合計 121 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002415_654561.png （合計 122 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002415_853793.png （合計 123 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002416_053607.png （合計 124 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002416_286896.png （合計 125 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002416_486989.png （合計 126 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002416_619523.png （合計 127 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002416_752980.png （合計 128 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002416_953054.png （合計 129 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002417_154088.png （合計 130 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002417_352931.png （合計 131 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002417_553030.png （合計 132 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002417_718932.png （合計 133 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002417_919812.png （合計 134 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002418_322872.png （合計 135 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002418_485358.png （合計 136 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002418_852096.png （合計 137 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002419_051841.png （合計 138 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002419_285612.png （合計 139 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002419_486871.png （合計 140 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002419_688663.png （合計 141 枚）\n",
      "[保存] Non Drowsy: dataset/Non_Drowsy/non_drowsy_20250813_002420_019631.png （合計 142 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002423_818810.png （合計 1 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002424_016372.png （合計 2 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002424_183044.png （合計 3 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002424_384268.png （合計 4 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002424_617442.png （合計 5 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002424_817381.png （合計 6 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002424_983646.png （合計 7 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002425_182810.png （合計 8 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002425_484513.png （合計 9 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002425_651225.png （合計 10 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002425_815966.png （合計 11 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002426_018080.png （合計 12 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002426_318179.png （合計 13 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002426_484098.png （合計 14 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002426_646435.png （合計 15 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002426_888700.png （合計 16 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002427_052960.png （合計 17 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002427_249349.png （合計 18 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002427_483074.png （合計 19 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002427_650454.png （合計 20 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002427_853131.png （合計 21 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002428_050964.png （合計 22 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002428_250817.png （合計 23 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002428_452147.png （合計 24 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002428_650550.png （合計 25 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002428_884341.png （合計 26 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002429_088430.png （合計 27 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002429_253673.png （合計 28 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002429_517555.png （合計 29 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002429_751913.png （合計 30 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002430_082778.png （合計 31 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002430_284325.png （合計 32 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002430_481143.png （合計 33 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002430_717700.png （合計 34 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002430_914830.png （合計 35 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002431_117426.png （合計 36 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002431_314445.png （合計 37 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002431_550606.png （合計 38 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002431_850704.png （合計 39 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002432_052878.png （合計 40 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002432_254306.png （合計 41 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002432_452904.png （合計 42 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002432_715679.png （合計 43 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002432_947696.png （合計 44 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002433_151210.png （合計 45 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002433_347864.png （合計 46 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002433_579081.png （合計 47 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002433_846626.png （合計 48 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002434_013213.png （合計 49 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002434_319269.png （合計 50 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002434_512897.png （合計 51 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002434_712104.png （合計 52 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002434_911942.png （合計 53 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002435_113081.png （合計 54 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002435_346579.png （合計 55 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002435_580599.png （合計 56 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002435_752544.png （合計 57 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002435_987706.png （合計 58 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002436_213155.png （合計 59 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002436_449168.png （合計 60 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002436_648280.png （合計 61 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002436_846331.png （合計 62 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002437_047392.png （合計 63 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002437_279588.png （合計 64 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002437_447205.png （合計 65 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002437_644815.png （合計 66 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002437_879594.png （合計 67 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002438_077892.png （合計 68 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002438_310530.png （合計 69 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002438_544327.png （合計 70 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002438_777814.png （合計 71 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002438_978441.png （合計 72 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002439_211102.png （合計 73 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002439_443933.png （合計 74 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002439_677926.png （合計 75 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002439_910591.png （合計 76 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002440_143941.png （合計 77 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002440_378262.png （合計 78 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002440_643050.png （合計 79 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002440_876856.png （合計 80 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002441_110917.png （合計 81 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002441_310685.png （合計 82 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002441_543842.png （合計 83 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002441_675625.png （合計 84 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002441_909832.png （合計 85 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002442_176301.png （合計 86 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002442_477032.png （合計 87 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002442_675962.png （合計 88 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002442_909365.png （合計 89 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002443_176283.png （合計 90 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002443_442326.png （合計 91 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002443_642516.png （合計 92 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002443_875986.png （合計 93 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002444_110471.png （合計 94 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002444_342994.png （合計 95 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002444_542102.png （合計 96 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002444_775274.png （合計 97 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002445_043055.png （合計 98 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002445_241774.png （合計 99 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002445_542435.png （合計 100 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002445_746016.png （合計 101 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002446_007970.png （合計 102 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002446_209121.png （合計 103 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002446_407295.png （合計 104 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002446_641081.png （合計 105 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002446_840571.png （合計 106 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002447_040570.png （合計 107 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002447_376345.png （合計 108 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002447_574216.png （合計 109 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002447_807368.png （合計 110 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002448_006486.png （合計 111 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002448_274783.png （合計 112 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002448_507377.png （合計 113 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002448_706608.png （合計 114 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002449_008457.png （合計 115 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002449_240445.png （合計 116 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002449_446727.png （合計 117 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002449_680093.png （合計 118 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002449_874594.png （合計 119 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002450_173987.png （合計 120 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002450_439847.png （合計 121 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002450_640334.png （合計 122 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002450_839239.png （合計 123 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002451_205853.png （合計 124 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002451_405873.png （合計 125 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002451_605109.png （合計 126 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002451_839068.png （合計 127 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002452_039145.png （合計 128 枚）\n",
      "[保存] Drowsy: dataset/Drowsy/drowsy_20250813_002452_204858.png （合計 129 枚）\n",
      "=== キャプチャ終了 ===\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m現在のセルまたは前のセルでコードを実行中に、カーネル (Kernel) がクラッシュしました。\n",
      "\u001b[1;31mエラーの原因を特定するには、セル内のコードを確認してください。\n",
      "\u001b[1;31m詳細については<a href='https://aka.ms/vscodeJupyterKernelCrash'>こちら</a>をクリックします。\n",
      "\u001b[1;31m詳細については、Jupyter <a href='command:jupyter.viewOutput'>ログ</a> を参照してください。"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# 保存先ディレクトリ\n",
    "dir_drowsy = \"dataset/Drowsy\"\n",
    "dir_non_drowsy = \"dataset/Non_Drowsy\"\n",
    "\n",
    "# ディレクトリ作成\n",
    "os.makedirs(dir_drowsy, exist_ok=True)\n",
    "os.makedirs(dir_non_drowsy, exist_ok=True)\n",
    "\n",
    "# カメラ起動\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "print(\"=== キャプチャ開始 ===\")\n",
    "print(\"Cキー: Drowsy に保存 / Oキー: Non Drowsy に保存 / Qキー: 終了\")\n",
    "\n",
    "count_drowsy = 0\n",
    "count_non_drowsy = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"カメラが見つかりません\")\n",
    "        break\n",
    "\n",
    "    # 表示\n",
    "    cv2.imshow(\"Capture\", frame)\n",
    "\n",
    "    # キー入力取得\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # Cキー → Drowsy保存\n",
    "    if key == ord('c'):\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n",
    "        filename = os.path.join(dir_drowsy, f\"drowsy_{timestamp}.png\")\n",
    "        cv2.imwrite(filename, frame)\n",
    "        count_drowsy += 1\n",
    "        print(f\"[保存] Drowsy: {filename} （合計 {count_drowsy} 枚）\")\n",
    "\n",
    "    # Oキー → Non Drowsy保存\n",
    "    elif key == ord('o'):\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n",
    "        filename = os.path.join(dir_non_drowsy, f\"non_drowsy_{timestamp}.png\")\n",
    "        cv2.imwrite(filename, frame)\n",
    "        count_non_drowsy += 1\n",
    "        print(f\"[保存] Non Drowsy: {filename} （合計 {count_non_drowsy} 枚）\")\n",
    "\n",
    "    # Qキー → 終了\n",
    "    elif key == ord('q'):\n",
    "        print(\"=== キャプチャ終了 ===\")\n",
    "        break\n",
    "\n",
    "# 後処理\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0465e69c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
